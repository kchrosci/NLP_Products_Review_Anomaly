{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "# PyTorch Packages\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, output_notebook, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool, NumeralTickFormatter\n",
    "from bokeh.palettes import Set3_12\n",
    "from bokeh.transform import jitter\n",
    "\n",
    "# SKLearn Packages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score)\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"dee8ea00-c373-467f-ba46-52045181df04\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"dee8ea00-c373-467f-ba46-52045181df04\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"dee8ea00-c373-467f-ba46-52045181df04\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie pliku CSV\n",
    "df = pd.read_csv('csv_data/preprocesed_files/normal_opinions.csv', sep=',')\n",
    "\n",
    "# Pobranie zawartości kolumny \"content\" jako listy zdań\n",
    "sentences = df['content'].tolist()\n",
    "\n",
    "# Obliczenie długości każdego zdania\n",
    "sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "\n",
    "# Wyświetlenie histogramu\n",
    "plt.hist(sentence_lengths, bins=50)\n",
    "plt.xlabel('Długość zdania')\n",
    "# plt.xlim(0, 50)  # Ograniczenie osi x do zakresu od 0 do 50\n",
    "plt.ylabel('Liczba zdań')\n",
    "plt.title('Histogram długości zdań')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only fraud transactions\n",
    "fraud_df = df[df['Class'] == 1]\n",
    "f_source = ColumnDataSource(data = dict(x = fraud_df['TimeNorm'].values,\n",
    "                                    y = fraud_df['Amount'].values))\n",
    "# get only normal transactions\n",
    "non_fraud_df = df[df['Class'] == 0]\n",
    "# Limit amount of data in plot\n",
    "sample_non_fraud = df.sample(frac=0.01, replace=False)\n",
    "norm_source = ColumnDataSource(data = dict(x = sample_non_fraud['TimeNorm'].values,\n",
    "                                    y = sample_non_fraud['Amount'].values))\n",
    "# create Bokeh figure\n",
    "p = figure(plot_width = 800, \n",
    "           toolbar_location = None, \n",
    "           title = 'Transactions by Time and Amount')\n",
    "\n",
    "# plot Normal Transactions\n",
    "p.circle(x=jitter('x', width=0.9, range=p.x_range), \n",
    "         y='y', color = Set3_12[4], \n",
    "         fill_alpha = 0.1, \n",
    "         source = norm_source)\n",
    "\n",
    "# plot fraud transactions\n",
    "p.circle(x=jitter('x', width=0.9,range=p.x_range), \n",
    "         y='y', color = Set3_12[3], \n",
    "         fill_alpha = 0.7, \n",
    "         source = f_source)\n",
    "\n",
    "#function to format plot\n",
    "p = format_plot(p, \"Time\", \"Amount\")\n",
    "\n",
    "p.yaxis[0].formatter = NumeralTickFormatter(format=\"$0,0\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(p, x_label, y_label):\n",
    "    p.grid.grid_line_color = None\n",
    "    p.background_fill_color = \"whitesmoke\"\n",
    "    p.axis.minor_tick_line_color = None\n",
    "    p.title.align = 'center'\n",
    "    p.title.text_font_size = \"18px\"\n",
    "    p.xaxis.axis_label = x_label\n",
    "    p.yaxis.axis_label = y_label\n",
    "    p.xaxis.axis_label_text_font_size = \"14px\"\n",
    "    p.yaxis.axis_label_text_font_size = \"14px\"\n",
    "    p.yaxis.axis_line_color = None\n",
    "    p.yaxis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"12px\"\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wczytanie pliku CSV\n",
    "df = pd.read_csv('csv_data/preprocesed_files/anomaly_opinions.csv', sep=',')\n",
    "\n",
    "# Pobranie zawartości kolumny \"content\" jako listy zdań\n",
    "sentences = df['content'].tolist()\n",
    "\n",
    "# Obliczenie długości każdego zdania\n",
    "sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "\n",
    "# Wyświetlenie histogramu\n",
    "plt.hist(sentence_lengths, bins=50)\n",
    "plt.xlabel('Długość zdania')\n",
    "# plt.xlim(0, 50)  # Ograniczenie osi x do zakresu od 0 do 50\n",
    "plt.ylabel('Liczba zdań')\n",
    "plt.title('Histogram długości zdań')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "anomaly_opinions = read_csv('csv_data/preprocesed_files/anomaly_opinions.csv', sep=',')\n",
    "normal_opinions = read_csv('csv_data/preprocesed_files/normal_opinions.csv', sep=',')\n",
    "anomaly_opinions = anomaly_opinions[\"content\"]\n",
    "normal_opinions = normal_opinions[\"content\"]\n",
    "\n",
    "#Podział normalnych opinii na część testową i treningowa, liczba normalnych opinii 12 936,do treningu wykorzystano 90%\n",
    "normal_opinions, normal_opinions_test = train_test_split(normal_opinions, test_size = 0.2, r)  \n",
    "anomaly_opinions['label'] = 1\n",
    "normal_opinions['label'] = 0\n",
    "\n",
    "print(\"Wykorzystane normalne opinie: \", len(normal_opinions))\n",
    "print(\"Wykorzystane anomalie: \", len(anomaly_opinions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicjalizacja modelu spaCy\n",
    "nlp = spacy.load('pl_core_news_md')\n",
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upraszczanie opini przed dodaniem do DataSet (lower case, tylko litery)\n",
    "def preprocess_review(review):\n",
    "    # Usunięcie niepotrzebnych znaków\n",
    "    cleaned_review = re.sub(r'[^a-zA-ZąćęłńóśźżĄĆĘŁŃÓŚŹŻ\\s]', '', review)\n",
    "    # Tokenizacja tekstu\n",
    "    cleaned_review = cleaned_review.lower()\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_preprocessing(token_list):\n",
    "    sequence = np.array([token.vector for token in token_list])\n",
    "    sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "    print(type(sequence))\n",
    "\n",
    "    print(sequence.size())\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_preprocessing(opinion):\n",
    "    token_list = []\n",
    "    doc = nlp(preprocess_review(opinion))\n",
    "    for token in doc:\n",
    "        #TODO: Check if neccesary.\n",
    "        if not token.is_stop:\n",
    "            #TODO:\n",
    "            #token_list.append(token.lemma)\n",
    "            token_list.append(token)\n",
    "    return token_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(review):\n",
    "    token_list = token_preprocessing(review)\n",
    "    sequence = tensor_preprocessing(token_list)\n",
    "    # Normalizacja wektorów\n",
    "    #sequence = nn.functional.normalize(sequence, p=1, dim=1)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasa Dataset do przechowywania danych opinii\n",
    "class OpinionDataset(Dataset):\n",
    "    def __init__(self, opinions):\n",
    "        self.opinions = opinions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.opinions)\n",
    "\n",
    "    #Metoda get_item bierze pojedyńczą opinie wykonuje na niej preprocess_review, następnie wykorzystuję metode nlp z biblioteki Spacy\n",
    "    #do tokenizacji. Następnie wyciąga wektor word embeddings po tokenizacji i z jego wykorzystaniem tworzy tensor. Ostatnim korkiem\n",
    "    #jest normalizacja tensora z wykorzystaniem normalizacji norma L1 (Manhattan norm)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.opinions[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie datasetów dla danych normalnych treningowych, testowych i opinii o podwójnej jakości\n",
    "normal_dataset = OpinionDataset(normal_opinions)\n",
    "anomalous_dataset = OpinionDataset(anomaly_opinions)\n",
    "normal_test_dataset = OpinionDataset(normal_opinions_test)\n",
    "\n",
    "# Wyliczenie maksymalnego rozmiaru sekwencji wektorów\n",
    "max_seq_len1 = max(len(opinion) for opinion in normal_dataset.opinions)\n",
    "max_seq_len2 = max(len(opinion) for opinion in anomalous_dataset.opinions)\n",
    "max_seq_len3 = max(len(opinion) for opinion in normal_test_dataset.opinions)\n",
    "max_seq_len = max(max_seq_len1, max_seq_len2, max_seq_len3)\n",
    "print(\"Maksymalna długość opinii: \",max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: DLACZEGO TO MA TAKI SIZE\n",
    "\n",
    "print(normal_dataset[0])\n",
    "print(len(normal_dataset[0]))\n",
    "preprocessing_pipeline(normal_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyrównanie rozmiarów sekwencji wektorów\n",
    "def pad_sequence(sequence, max_len):\n",
    "    if sequence.size(0) == 0:\n",
    "        return torch.zeros(max_len, 300)\n",
    "    else:\n",
    "        padded_seq = torch.zeros(max_len, sequence.size(1))\n",
    "        padded_seq[:sequence.size(0)] = sequence\n",
    "        return padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dostosowanie sekwencji wektorów do maksymalnego rozmiaru\n",
    "normal_dataset = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in normal_dataset]\n",
    "anomalous_dataset = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in anomalous_dataset]\n",
    "normal_dataset_test = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in normal_test_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja autoenkodera\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim // 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(input_dim // 4, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wielkość wejściowa\n",
    "input_dim = normal_dataset[0].size(1)\n",
    "\n",
    "# Inicjalizacja modelu autoenkodera\n",
    "autoencoder = Autoencoder(input_dim)\n",
    "\n",
    "# Definicja funkcji straty i optymalizatora\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0001)\n",
    "\n",
    "# Inicjalizacja pustej macierzy pomyłek\n",
    "cm = torch.zeros((2, 2), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja obliczająca próg na podstawie kwantyla\n",
    "def calc_threshold(values, quantile):\n",
    "    return torch.quantile(values, quantile)\n",
    "\n",
    "\n",
    "# Funkcja trenująca autoenkodera\n",
    "def train_autoencoder(model, dataloader, criterion, optimizer, quantile, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = batch.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Obliczanie macierzy pomyłek\n",
    "            with torch.no_grad():\n",
    "                autoencoder.eval()\n",
    "                mse_loss = nn.MSELoss(reduction='none')\n",
    "                loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "                is_anomalous = torch.where(loss_values > calc_threshold(loss_values, quantile), 1, 0)\n",
    "\n",
    "                for label in is_anomalous:\n",
    "                    cm[label][label] += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return calc_threshold(loss_values, quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie DataLoader dla danych normalnych\n",
    "normal_dataloader = DataLoader(normal_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Ustal wartość kwantyla\n",
    "quantile = 0.87\n",
    "\n",
    "# Trenowanie autoenkodera\n",
    "threshold = train_autoencoder(autoencoder, normal_dataloader, criterion, optimizer, quantile, num_epochs=10)\n",
    "print(\"Wyznaczony próg: \", threshold.real)\n",
    "print(\"\")\n",
    "\n",
    "# Wyświetlanie macierzy pomyłek\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializacja macierzy cm\n",
    "cm = torch.zeros((2, 2), dtype=torch.int)\n",
    "\n",
    "# Testowanie na opiniach nieświadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    for batch in DataLoader(normal_dataset_test, batch_size=1):\n",
    "        inputs = batch.float()\n",
    "        outputs = autoencoder(inputs)\n",
    "        mse_loss = nn.MSELoss(reduction='none')\n",
    "        loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "        is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "        cm[0][is_anomalous] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testowanie na opiniach świadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    for batch in DataLoader(anomalous_dataset, batch_size=1):\n",
    "        inputs = batch.float()\n",
    "        outputs = autoencoder(inputs)\n",
    "        mse_loss = nn.MSELoss(reduction='none')\n",
    "        loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "        print(loss_values)\n",
    "        is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "        cm[1][is_anomalous] += 1\n",
    "\n",
    "# Obliczenie sumy wierszy i kolumn macierzy pomyłek\n",
    "sum_rows = torch.sum(cm, dim=1)\n",
    "sum_cols = torch.sum(cm, dim=0)\n",
    "\n",
    "# Obliczenie liczby prawdziwie negatywnych, fałszywie negatywnych, fałszywie pozytywnych i prawdziwie pozytywnych\n",
    "tn = cm[0][0]\n",
    "fn = cm[0][1]\n",
    "fp = cm[1][0]\n",
    "tp = cm[1][1]\n",
    "\n",
    "# Wyświetlenie macierzy pomyłek\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Wyświetlenie innych metryk oceny\n",
    "print(\"Liczba prawdziwie negatywnych (TN):\", tn.item())\n",
    "print(\"Liczba fałszywie negatywnych (FN):\", fn.item())\n",
    "print(\"Liczba fałszywie pozytywnych (FP):\", fp.item())\n",
    "print(\"Liczba prawdziwie pozytywnych (TP):\", tp.item())\n",
    "print()\n",
    "\n",
    "accuracy = (tn + tp) / (tn + fn + fp + tp)\n",
    "print(\"Accuracy:\", accuracy.item())\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision:\", precision.item())\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Recall:\", recall.item())\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1-Score:\", f1_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Przygotuj tekst testowy\n",
    "text = \"mój polski proszek jest gorszy niż niemiecki niż\"\n",
    "\n",
    "\n",
    "preprocessed_text = pad_sequence(preprocessing_pipeline(text), max_seq_len)\n",
    "\n",
    "\n",
    "# Przekonwertuj przetworzony tekst na tensor PyTorch\n",
    "test_data = torch.Tensor(preprocessed_text)\n",
    "\n",
    "# Przekaż dane testowe przez model\n",
    "decoded_data = autoencoder(test_data)\n",
    "\n",
    "# Testowanie na opiniach nieświadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    \n",
    "    inputs = test_data\n",
    "    outputs = autoencoder(inputs)\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    loss_values = mse_loss(outputs, inputs).mean()\n",
    "    print(loss_values)\n",
    "    is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "    print(is_anomalous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
