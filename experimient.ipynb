{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.lang.pl.stop_words import STOP_WORDS\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pandas import read_csv\n",
    "import pandas as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykorzystane normalne opinie:  200\n",
      "Wykorzystane anomalie:  76\n"
     ]
    }
   ],
   "source": [
    "# Wczytanie danych\n",
    "anomaly_opinions = read_csv('csv_data/preprocesed_files/anomaly_opinions.csv', sep=',')\n",
    "normal_opinions = read_csv('csv_data/preprocesed_files/normal_opinions.csv', sep=',')\n",
    "anomaly_opinions = anomaly_opinions[\"content\"].values.tolist()\n",
    "normal_opinions = normal_opinions[\"content\"].values.tolist()\n",
    "\n",
    "#Podział normalnych opinii na część testową i treningowa, liczba normalnych opinii 12 936,do treningu wykorzystano 90%\n",
    "normal_opinions_test = normal_opinions[300:400]\n",
    "normal_opinions = normal_opinions[:200]\n",
    "\n",
    "print(\"Wykorzystane normalne opinie: \", len(normal_opinions))\n",
    "print(\"Wykorzystane anomalie: \", len(anomaly_opinions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'morphologizer',\n",
       " 'parser',\n",
       " 'lemmatizer',\n",
       " 'tagger',\n",
       " 'attribute_ruler',\n",
       " 'ner']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicjalizacja modelu spaCy\n",
    "nlp = spacy.load('pl_core_news_md')\n",
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upraszczanie opini przed dodaniem do DataSet (lower case, tylko litery)\n",
    "def preprocess_review(review):\n",
    "    # Usunięcie niepotrzebnych znaków\n",
    "    cleaned_review = re.sub(r'[^a-zA-ZąćęłńóśźżĄĆĘŁŃÓŚŹŻ\\s]', '', review)\n",
    "    # Tokenizacja tekstu\n",
    "    cleaned_review = cleaned_review.lower()\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_preprocessing(token_list):\n",
    "    sequence = np.array([token.vector for token in token_list])\n",
    "    sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_preprocessing(opinion):\n",
    "    token_list = []\n",
    "    doc = nlp(preprocess_review(opinion))\n",
    "    for token in doc:\n",
    "        #TODO: Check if neccesary.\n",
    "        if not token.is_stop:\n",
    "            #TODO:\n",
    "            #token_list.append(token.lemma)\n",
    "            token_list.append(token)\n",
    "    return token_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(review):\n",
    "    token_list = token_preprocessing(review)\n",
    "    sequence = tensor_preprocessing(token_list)\n",
    "    # Normalizacja wektorów\n",
    "    #sequence = nn.functional.normalize(sequence, p=1, dim=1)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasa Dataset do przechowywania danych opinii\n",
    "class OpinionDataset(Dataset):\n",
    "    def __init__(self, opinions):\n",
    "        self.opinions = opinions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.opinions)\n",
    "\n",
    "    #Metoda get_item bierze pojedyńczą opinie wykonuje na niej preprocess_review, następnie wykorzystuję metode nlp z biblioteki Spacy\n",
    "    #do tokenizacji. Następnie wyciąga wektor word embeddings po tokenizacji i z jego wykorzystaniem tworzy tensor. Ostatnim korkiem\n",
    "    #jest normalizacja tensora z wykorzystaniem normalizacji norma L1 (Manhattan norm)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.opinions[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maksymalna długość opinii:  1430\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie datasetów dla danych normalnych treningowych, testowych i opinii o podwójnej jakości\n",
    "normal_dataset = OpinionDataset(normal_opinions)\n",
    "anomalous_dataset = OpinionDataset(anomaly_opinions)\n",
    "normal_test_dataset = OpinionDataset(normal_opinions_test)\n",
    "\n",
    "# Wyliczenie maksymalnego rozmiaru sekwencji wektorów\n",
    "max_seq_len1 = max(len(opinion) for opinion in normal_dataset.opinions)\n",
    "max_seq_len2 = max(len(opinion) for opinion in anomalous_dataset.opinions)\n",
    "max_seq_len3 = max(len(opinion) for opinion in normal_test_dataset.opinions)\n",
    "max_seq_len = max(max_seq_len1, max_seq_len2, max_seq_len3)\n",
    "print(\"Maksymalna długość opinii: \",max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyrównanie rozmiarów sekwencji wektorów\n",
    "def pad_sequence(sequence, max_len):\n",
    "    if sequence.size(0) == 0:\n",
    "        return torch.zeros(max_len, 300)\n",
    "    else:\n",
    "        padded_seq = torch.zeros(max_len, sequence.size(1))\n",
    "        padded_seq[:sequence.size(0)] = sequence\n",
    "        return padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[biedronka, chodzi, nodze, łaskocze, rowerzyste]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_preprocessing(\"biedronka chodzi po nodze i łaskocze rowerzyste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dostosowanie sekwencji wektorów do maksymalnego rozmiaru\n",
    "normal_dataset = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in normal_dataset]\n",
    "anomalous_dataset = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in anomalous_dataset]\n",
    "normal_dataset_test = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in normal_test_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja autoenkodera\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim // 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(input_dim // 4, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wielkość wejściowa\n",
    "input_dim = normal_dataset[0].size(1)\n",
    "\n",
    "# Inicjalizacja modelu autoenkodera\n",
    "autoencoder = Autoencoder(input_dim)\n",
    "\n",
    "# Definicja funkcji straty i optymalizatora\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0001)\n",
    "\n",
    "# Inicjalizacja pustej macierzy pomyłek\n",
    "cm = torch.zeros((2, 2), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja obliczająca próg na podstawie kwantyla\n",
    "def calc_threshold(values, quantile):\n",
    "    return torch.quantile(values, quantile)\n",
    "\n",
    "\n",
    "# Funkcja trenująca autoenkodera\n",
    "def train_autoencoder(model, dataloader, criterion, optimizer, quantile, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = batch.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Obliczanie macierzy pomyłek\n",
    "            with torch.no_grad():\n",
    "                autoencoder.eval()\n",
    "                mse_loss = nn.MSELoss(reduction='none')\n",
    "                loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "                is_anomalous = torch.where(loss_values > calc_threshold(loss_values, quantile), 1, 0)\n",
    "\n",
    "                for label in is_anomalous:\n",
    "                    cm[label][label] += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return calc_threshold(loss_values, quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.2617\n",
      "Epoch 2/10, Loss: 0.2601\n",
      "Epoch 3/10, Loss: 0.2590\n",
      "Epoch 4/10, Loss: 0.2582\n",
      "Epoch 5/10, Loss: 0.2570\n",
      "Epoch 6/10, Loss: 0.2558\n",
      "Epoch 7/10, Loss: 0.2555\n",
      "Epoch 8/10, Loss: 0.2537\n",
      "Epoch 9/10, Loss: 0.2518\n",
      "Epoch 10/10, Loss: 0.2514\n",
      "Wyznaczony próg:  tensor(0.2700)\n",
      "\n",
      "Macierz pomyłek:\n",
      "tensor([[1690,    0],\n",
      "        [   0,  310]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Tworzenie DataLoader dla danych normalnych\n",
    "normal_dataloader = DataLoader(normal_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Ustal wartość kwantyla\n",
    "quantile = 0.87\n",
    "\n",
    "# Trenowanie autoenkodera\n",
    "threshold = train_autoencoder(autoencoder, normal_dataloader, criterion, optimizer, quantile, num_epochs=10)\n",
    "print(\"Wyznaczony próg: \", threshold.real)\n",
    "print(\"\")\n",
    "\n",
    "# Wyświetlanie macierzy pomyłek\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializacja macierzy cm\n",
    "cm = torch.zeros((2, 2), dtype=torch.int)\n",
    "\n",
    "# Testowanie na opiniach nieświadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    for batch in DataLoader(normal_dataset_test, batch_size=1):\n",
    "        inputs = batch.float()\n",
    "        outputs = autoencoder(inputs)\n",
    "        mse_loss = nn.MSELoss(reduction='none')\n",
    "        loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "        is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "        cm[0][is_anomalous] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2521])\n",
      "tensor([0.2420])\n",
      "tensor([0.2827])\n",
      "tensor([0.2459])\n",
      "tensor([0.2481])\n",
      "tensor([0.2506])\n",
      "tensor([0.2671])\n",
      "tensor([0.2653])\n",
      "tensor([0.2777])\n",
      "tensor([0.3080])\n",
      "tensor([0.2444])\n",
      "tensor([0.2457])\n",
      "tensor([0.2598])\n",
      "tensor([0.2485])\n",
      "tensor([0.3568])\n",
      "tensor([0.2487])\n",
      "tensor([0.2485])\n",
      "tensor([0.2552])\n",
      "tensor([0.2434])\n",
      "tensor([0.2593])\n",
      "tensor([0.2502])\n",
      "tensor([0.2488])\n",
      "tensor([0.2441])\n",
      "tensor([0.2485])\n",
      "tensor([0.2659])\n",
      "tensor([0.2434])\n",
      "tensor([0.2739])\n",
      "tensor([0.2450])\n",
      "tensor([0.2536])\n",
      "tensor([0.2460])\n",
      "tensor([0.2423])\n",
      "tensor([0.2515])\n",
      "tensor([0.2422])\n",
      "tensor([0.2443])\n",
      "tensor([0.2514])\n",
      "tensor([0.2544])\n",
      "tensor([0.2448])\n",
      "tensor([0.2556])\n",
      "tensor([0.2528])\n",
      "tensor([0.2506])\n",
      "tensor([0.2864])\n",
      "tensor([0.2575])\n",
      "tensor([0.2584])\n",
      "tensor([0.4626])\n",
      "tensor([0.2488])\n",
      "tensor([0.2526])\n",
      "tensor([0.2466])\n",
      "tensor([0.2675])\n",
      "tensor([0.2407])\n",
      "tensor([0.2528])\n",
      "tensor([0.2694])\n",
      "tensor([0.5654])\n",
      "tensor([0.2653])\n",
      "tensor([0.2586])\n",
      "tensor([0.3264])\n",
      "tensor([0.2882])\n",
      "tensor([0.2973])\n",
      "tensor([0.2536])\n",
      "tensor([0.2420])\n",
      "tensor([0.2620])\n",
      "tensor([0.2661])\n",
      "tensor([0.2830])\n",
      "tensor([0.2532])\n",
      "tensor([0.2587])\n",
      "tensor([0.2541])\n",
      "tensor([0.2488])\n",
      "tensor([0.2507])\n",
      "tensor([0.2470])\n",
      "tensor([0.2484])\n",
      "tensor([0.2530])\n",
      "tensor([0.2491])\n",
      "tensor([0.2392])\n",
      "tensor([0.2416])\n",
      "tensor([0.2872])\n",
      "tensor([0.2649])\n",
      "tensor([0.2597])\n",
      "Macierz pomyłek:\n",
      "tensor([[94,  6],\n",
      "        [63, 13]], dtype=torch.int32)\n",
      "\n",
      "Liczba prawdziwie negatywnych (TN): 94\n",
      "Liczba fałszywie negatywnych (FN): 6\n",
      "Liczba fałszywie pozytywnych (FP): 63\n",
      "Liczba prawdziwie pozytywnych (TP): 13\n",
      "\n",
      "Accuracy: 0.6079545617103577\n",
      "Precision: 0.17105263471603394\n",
      "Recall: 0.6842105388641357\n",
      "F1-Score: 0.27368420362472534\n"
     ]
    }
   ],
   "source": [
    "# Testowanie na opiniach świadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    for batch in DataLoader(anomalous_dataset, batch_size=1):\n",
    "        inputs = batch.float()\n",
    "        outputs = autoencoder(inputs)\n",
    "        mse_loss = nn.MSELoss(reduction='none')\n",
    "        loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "        print(loss_values)\n",
    "        is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "        cm[1][is_anomalous] += 1\n",
    "\n",
    "# Obliczenie sumy wierszy i kolumn macierzy pomyłek\n",
    "sum_rows = torch.sum(cm, dim=1)\n",
    "sum_cols = torch.sum(cm, dim=0)\n",
    "\n",
    "# Obliczenie liczby prawdziwie negatywnych, fałszywie negatywnych, fałszywie pozytywnych i prawdziwie pozytywnych\n",
    "tn = cm[0][0]\n",
    "fn = cm[0][1]\n",
    "fp = cm[1][0]\n",
    "tp = cm[1][1]\n",
    "\n",
    "# Wyświetlenie macierzy pomyłek\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Wyświetlenie innych metryk oceny\n",
    "print(\"Liczba prawdziwie negatywnych (TN):\", tn.item())\n",
    "print(\"Liczba fałszywie negatywnych (FN):\", fn.item())\n",
    "print(\"Liczba fałszywie pozytywnych (FP):\", fp.item())\n",
    "print(\"Liczba prawdziwie pozytywnych (TP):\", tp.item())\n",
    "print()\n",
    "\n",
    "accuracy = (tn + tp) / (tn + fn + fp + tp)\n",
    "print(\"Accuracy:\", accuracy.item())\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision:\", precision.item())\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Recall:\", recall.item())\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1-Score:\", f1_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4301, 0.4315, 0.4572,  ..., 0.5225, 0.4149, 0.3856],\n",
      "        [0.5073, 0.4449, 0.4475,  ..., 0.5277, 0.4043, 0.4078],\n",
      "        [0.4765, 0.4636, 0.4497,  ..., 0.4941, 0.3964, 0.3815],\n",
      "        [0.4723, 0.4690, 0.4612,  ..., 0.5199, 0.4546, 0.4479],\n",
      "        [0.3751, 0.3974, 0.3935,  ..., 0.5223, 0.3143, 0.3048]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2410)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Przygotuj tekst testowy\n",
    "text = \"gorszy od niemieckiego\"\n",
    "\n",
    "# Przetwórz tekst przy użyciu preprocessing_pipeline (o ile jest dostępny)\n",
    "\n",
    "\n",
    "preprocessed_text = pad_sequence(preprocessing_pipeline(text), max_seq_len)\n",
    "\n",
    "\n",
    "# Przekonwertuj przetworzony tekst na tensor PyTorch\n",
    "test_data = torch.Tensor(preprocessed_text)\n",
    "\n",
    "# Przekaż dane testowe przez model\n",
    "decoded_data = autoencoder(test_data)\n",
    "\n",
    "# Testowanie na opiniach nieświadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    \n",
    "    inputs = test_data\n",
    "    outputs = autoencoder(inputs)\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    loss_values = mse_loss(outputs, inputs).mean()\n",
    "    print(loss_values)\n",
    "    is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "    print(is_anomalous)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
