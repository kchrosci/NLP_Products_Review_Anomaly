{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.lang.pl.stop_words import STOP_WORDS\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pandas import read_csv\n",
    "import pandas as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wczytanie pliku CSV\n",
    "df = pd.read_csv('csv_data/preprocesed_files/normal_opinions.csv', sep=',')\n",
    "\n",
    "# Pobranie zawartości kolumny \"content\" jako listy zdań\n",
    "sentences = df['content'].tolist()\n",
    "\n",
    "# Obliczenie długości każdego zdania\n",
    "sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "\n",
    "# Wyświetlenie histogramu\n",
    "plt.hist(sentence_lengths, bins=50)\n",
    "plt.xlabel('Długość zdania')\n",
    "# plt.xlim(0, 50)  # Ograniczenie osi x do zakresu od 0 do 50\n",
    "plt.ylabel('Liczba zdań')\n",
    "plt.title('Histogram długości zdań')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wczytanie pliku CSV\n",
    "df = pd.read_csv('csv_data/preprocesed_files/anomaly_opinions.csv', sep=',')\n",
    "\n",
    "# Pobranie zawartości kolumny \"content\" jako listy zdań\n",
    "sentences = df['content'].tolist()\n",
    "\n",
    "# Obliczenie długości każdego zdania\n",
    "sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "\n",
    "# Wyświetlenie histogramu\n",
    "plt.hist(sentence_lengths, bins=50)\n",
    "plt.xlabel('Długość zdania')\n",
    "# plt.xlim(0, 50)  # Ograniczenie osi x do zakresu od 0 do 50\n",
    "plt.ylabel('Liczba zdań')\n",
    "plt.title('Histogram długości zdań')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "anomaly_opinions = read_csv('csv_data/preprocesed_files/anomaly_opinions.csv', sep=',')\n",
    "normal_opinions = read_csv('csv_data/preprocesed_files/normal_opinions.csv', sep=',')\n",
    "anomaly_opinions = anomaly_opinions[\"content\"].values.tolist()\n",
    "normal_opinions = normal_opinions[\"content\"].values.tolist()\n",
    "\n",
    "#Podział normalnych opinii na część testową i treningowa, liczba normalnych opinii 12 936,do treningu wykorzystano 90%\n",
    "normal_opinions, normal_opinions_test = train_test_split(normal_opinions, test_size = 0.2)  \n",
    "\n",
    "\n",
    "print(\"Wykorzystane normalne opinie: \", len(normal_opinions))\n",
    "print(\"Wykorzystane anomalie: \", len(anomaly_opinions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicjalizacja modelu spaCy\n",
    "nlp = spacy.load('pl_core_news_md')\n",
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upraszczanie opini przed dodaniem do DataSet (lower case, tylko litery)\n",
    "def preprocess_review(review):\n",
    "    # Usunięcie niepotrzebnych znaków\n",
    "    cleaned_review = re.sub(r'[^a-zA-ZąćęłńóśźżĄĆĘŁŃÓŚŹŻ\\s]', '', review)\n",
    "    # Tokenizacja tekstu\n",
    "    cleaned_review = cleaned_review.lower()\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_preprocessing(token_list):\n",
    "    sequence = np.array([token.vector for token in token_list])\n",
    "    sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "    print(type(sequence))\n",
    "\n",
    "    print(sequence.size())\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_preprocessing(opinion):\n",
    "    token_list = []\n",
    "    doc = nlp(preprocess_review(opinion))\n",
    "    for token in doc:\n",
    "        #TODO: Check if neccesary.\n",
    "        if not token.is_stop:\n",
    "            #TODO:\n",
    "            #token_list.append(token.lemma)\n",
    "            token_list.append(token)\n",
    "    return token_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(review):\n",
    "    token_list = token_preprocessing(review)\n",
    "    sequence = tensor_preprocessing(token_list)\n",
    "    # Normalizacja wektorów\n",
    "    #sequence = nn.functional.normalize(sequence, p=1, dim=1)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasa Dataset do przechowywania danych opinii\n",
    "class OpinionDataset(Dataset):\n",
    "    def __init__(self, opinions):\n",
    "        self.opinions = opinions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.opinions)\n",
    "\n",
    "    #Metoda get_item bierze pojedyńczą opinie wykonuje na niej preprocess_review, następnie wykorzystuję metode nlp z biblioteki Spacy\n",
    "    #do tokenizacji. Następnie wyciąga wektor word embeddings po tokenizacji i z jego wykorzystaniem tworzy tensor. Ostatnim korkiem\n",
    "    #jest normalizacja tensora z wykorzystaniem normalizacji norma L1 (Manhattan norm)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.opinions[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie datasetów dla danych normalnych treningowych, testowych i opinii o podwójnej jakości\n",
    "normal_dataset = OpinionDataset(normal_opinions)\n",
    "anomalous_dataset = OpinionDataset(anomaly_opinions)\n",
    "normal_test_dataset = OpinionDataset(normal_opinions_test)\n",
    "\n",
    "# Wyliczenie maksymalnego rozmiaru sekwencji wektorów\n",
    "max_seq_len1 = max(len(opinion) for opinion in normal_dataset.opinions)\n",
    "max_seq_len2 = max(len(opinion) for opinion in anomalous_dataset.opinions)\n",
    "max_seq_len3 = max(len(opinion) for opinion in normal_test_dataset.opinions)\n",
    "max_seq_len = max(max_seq_len1, max_seq_len2, max_seq_len3)\n",
    "print(\"Maksymalna długość opinii: \",max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: DLACZEGO TO MA TAKI SIZE\n",
    "\n",
    "print(normal_dataset[0])\n",
    "print(len(normal_dataset[0]))\n",
    "preprocessing_pipeline(normal_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyrównanie rozmiarów sekwencji wektorów\n",
    "def pad_sequence(sequence, max_len):\n",
    "    if sequence.size(0) == 0:\n",
    "        return torch.zeros(max_len, 300)\n",
    "    else:\n",
    "        padded_seq = torch.zeros(max_len, sequence.size(1))\n",
    "        padded_seq[:sequence.size(0)] = sequence\n",
    "        return padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dostosowanie sekwencji wektorów do maksymalnego rozmiaru\n",
    "normal_dataset = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in normal_dataset]\n",
    "anomalous_dataset = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in anomalous_dataset]\n",
    "normal_dataset_test = [pad_sequence(preprocessing_pipeline(opinion), max_seq_len) for opinion in normal_test_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja autoenkodera\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim // 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(input_dim // 4, input_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wielkość wejściowa\n",
    "input_dim = normal_dataset[0].size(1)\n",
    "\n",
    "# Inicjalizacja modelu autoenkodera\n",
    "autoencoder = Autoencoder(input_dim)\n",
    "\n",
    "# Definicja funkcji straty i optymalizatora\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0001)\n",
    "\n",
    "# Inicjalizacja pustej macierzy pomyłek\n",
    "cm = torch.zeros((2, 2), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja obliczająca próg na podstawie kwantyla\n",
    "def calc_threshold(values, quantile):\n",
    "    return torch.quantile(values, quantile)\n",
    "\n",
    "\n",
    "# Funkcja trenująca autoenkodera\n",
    "def train_autoencoder(model, dataloader, criterion, optimizer, quantile, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = batch.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Obliczanie macierzy pomyłek\n",
    "            with torch.no_grad():\n",
    "                autoencoder.eval()\n",
    "                mse_loss = nn.MSELoss(reduction='none')\n",
    "                loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "                is_anomalous = torch.where(loss_values > calc_threshold(loss_values, quantile), 1, 0)\n",
    "\n",
    "                for label in is_anomalous:\n",
    "                    cm[label][label] += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return calc_threshold(loss_values, quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie DataLoader dla danych normalnych\n",
    "normal_dataloader = DataLoader(normal_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Ustal wartość kwantyla\n",
    "quantile = 0.87\n",
    "\n",
    "# Trenowanie autoenkodera\n",
    "threshold = train_autoencoder(autoencoder, normal_dataloader, criterion, optimizer, quantile, num_epochs=10)\n",
    "print(\"Wyznaczony próg: \", threshold.real)\n",
    "print(\"\")\n",
    "\n",
    "# Wyświetlanie macierzy pomyłek\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializacja macierzy cm\n",
    "cm = torch.zeros((2, 2), dtype=torch.int)\n",
    "\n",
    "# Testowanie na opiniach nieświadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    for batch in DataLoader(normal_dataset_test, batch_size=1):\n",
    "        inputs = batch.float()\n",
    "        outputs = autoencoder(inputs)\n",
    "        mse_loss = nn.MSELoss(reduction='none')\n",
    "        loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "        is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "        cm[0][is_anomalous] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testowanie na opiniach świadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    for batch in DataLoader(anomalous_dataset, batch_size=1):\n",
    "        inputs = batch.float()\n",
    "        outputs = autoencoder(inputs)\n",
    "        mse_loss = nn.MSELoss(reduction='none')\n",
    "        loss_values = mse_loss(outputs, inputs).mean(dim=(1, 2))\n",
    "        print(loss_values)\n",
    "        is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "        cm[1][is_anomalous] += 1\n",
    "\n",
    "# Obliczenie sumy wierszy i kolumn macierzy pomyłek\n",
    "sum_rows = torch.sum(cm, dim=1)\n",
    "sum_cols = torch.sum(cm, dim=0)\n",
    "\n",
    "# Obliczenie liczby prawdziwie negatywnych, fałszywie negatywnych, fałszywie pozytywnych i prawdziwie pozytywnych\n",
    "tn = cm[0][0]\n",
    "fn = cm[0][1]\n",
    "fp = cm[1][0]\n",
    "tp = cm[1][1]\n",
    "\n",
    "# Wyświetlenie macierzy pomyłek\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Wyświetlenie innych metryk oceny\n",
    "print(\"Liczba prawdziwie negatywnych (TN):\", tn.item())\n",
    "print(\"Liczba fałszywie negatywnych (FN):\", fn.item())\n",
    "print(\"Liczba fałszywie pozytywnych (FP):\", fp.item())\n",
    "print(\"Liczba prawdziwie pozytywnych (TP):\", tp.item())\n",
    "print()\n",
    "\n",
    "accuracy = (tn + tp) / (tn + fn + fp + tp)\n",
    "print(\"Accuracy:\", accuracy.item())\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision:\", precision.item())\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Recall:\", recall.item())\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1-Score:\", f1_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Przygotuj tekst testowy\n",
    "text = \"mój polski proszek jest gorszy niż niemiecki niż\"\n",
    "\n",
    "\n",
    "preprocessed_text = pad_sequence(preprocessing_pipeline(text), max_seq_len)\n",
    "\n",
    "\n",
    "# Przekonwertuj przetworzony tekst na tensor PyTorch\n",
    "test_data = torch.Tensor(preprocessed_text)\n",
    "\n",
    "# Przekaż dane testowe przez model\n",
    "decoded_data = autoencoder(test_data)\n",
    "\n",
    "# Testowanie na opiniach nieświadczących o podwójnej jakości\n",
    "with torch.no_grad():\n",
    "    autoencoder.eval()\n",
    "    \n",
    "    inputs = test_data\n",
    "    outputs = autoencoder(inputs)\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    loss_values = mse_loss(outputs, inputs).mean()\n",
    "    print(loss_values)\n",
    "    is_anomalous = torch.where(loss_values > threshold, 1, 0)\n",
    "    print(is_anomalous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
