{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "# Załadowanie modelu języka polskiego\n",
    "nlp = spacy.load('pl_core_news_md')\n",
    "anomaly_opinions = pd.read_csv('csv_data/preprocesed_files/anomaly_opinions.csv')\n",
    "normal_opinions = pd.read_csv('csv_data/preprocesed_files/normal_opinions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def unique_words_in_csv(file_path, column_name):\n",
    "    lem_counter = Counter()\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    content_column = df[column_name]\n",
    "\n",
    "    for content in content_column:\n",
    "        doc = nlp(content)\n",
    "\n",
    "        for token in doc:\n",
    "            if token.is_alpha and (not token.is_stop or token.lower_ == \"niż\" or token.lower_ == \"od\"):\n",
    "                lem_counter[token.lemma_.lower()] += 1\n",
    "\n",
    "    lemmas_count = list(zip(lem_counter.keys(), lem_counter.values()))\n",
    "    sorted_lemmas_count = sorted(lemmas_count, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_lemmas_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykładowe użycie\n",
    "file_path = 'csv_data/preprocesed_files/anomaly_opinions.csv'\n",
    "column_name = 'content'\n",
    "\n",
    "lemmas_count = unique_words_in_csv(file_path, column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lemmas_in_dataset(sorted_lemmas_count):\n",
    "    # Przygotowanie danych do wykresu\n",
    "    words = [lemma for lemma, count in sorted_lemmas_count if count > 5]\n",
    "    counts = [count for lemma, count in sorted_lemmas_count if count > 5]\n",
    "\n",
    "    # Generowanie wykresu słupkowego\n",
    "    plt.figure(figsize=(10, 6))  # Zmiana rozmiaru wykresu\n",
    "    plt.bar(range(len(words)), counts)\n",
    "    plt.xticks(range(len(words)), words, rotation=45, ha='right')  # Obrót etykiet o 45 stopni\n",
    "    plt.xlabel(\"Unikalne Słowa\")\n",
    "    plt.ylabel(\"Częstość występowania\")\n",
    "    plt.title(\"Częstość występowania unikalnych słów (częstość > 5)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_lemmas_in_dataset(lemmas_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicjalizacja pustej listy\n",
    "lemmas = []\n",
    "\n",
    "# Iteracja po liście lemmas_count\n",
    "for lemma, count in lemmas_count:\n",
    "    if count > 5:\n",
    "        lemmas.append(lemma)\n",
    "len(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_combinations(manually_selected_lemmas, lemmas):\n",
    "    combinations = set()\n",
    "\n",
    "    # Generowanie wszystkich kombinacji bez duplikatów\n",
    "    for r in range(1, len(manually_selected_lemmas) + 1):\n",
    "        for combination in itertools.combinations(lemmas, r):\n",
    "            combinations.add(tuple(sorted(manually_selected_lemmas + list(combination))))\n",
    "\n",
    "    return combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_selected_lemmas = [\"niż\", \"lepszy\", \"lepiej\", \"rynek\", \"jakość\", \"znacznie\", \"od\"]\n",
    "\n",
    "combinations = create_combinations(manually_selected_lemmas, lemmas)\n",
    "\n",
    "for combination in combinations:\n",
    "    print(combination)\n",
    "\n",
    "print(\"Liczba kombinacji:\", len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rules_from_lemmas(lemmas):\n",
    "    rules = []\n",
    "\n",
    "    # Tworzenie reguł na podstawie analizy częstych kombinacji\n",
    "    for i in range(len(lemmas)):\n",
    "        for j in range(i + 1, len(lemmas)):\n",
    "            combination = (lemmas[i], lemmas[j])\n",
    "            rule = ' '.join(combination)  # Tworzenie reguły przez połączenie słów\n",
    "\n",
    "            rules.append(rule)  # Dodawanie reguły do zbioru\n",
    "\n",
    "    return rules\n",
    "\n",
    "\n",
    "rules = create_rules_from_lemmas(lemmas)\n",
    "\n",
    "for rule in rules:\n",
    "    print(rule)\n",
    "\n",
    "len(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dual_quality_opinion(zdanie):\n",
    "    # Przetworzenie zdania na tokeny\n",
    "    doc = nlp(zdanie)\n",
    "\n",
    "    # Tworzenie listy lematów zdania\n",
    "    #TU CHYBA TEŻTRZEBA DAĆ ZEBY NIE USUWAŁO NAM \"NIŻ\"\n",
    "    lemmas = [token.lemma_.lower() for token in doc]\n",
    "\n",
    "    # Przetworzenie lematów na zdanie\n",
    "    processed_sentence = ' '.join(lemmas)\n",
    "\n",
    "    # Sprawdzenie czy występują lematy słów kluczowych w zdaniu\n",
    "    for rule in rules:\n",
    "        if rule in processed_sentence:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Przykładowe zdania do sprawdzenia\n",
    "zdanie1 = \"Vizir jak Vizir. Trochę lepszy niż dostępny w polskich sklepach.\"\n",
    "zdanie2 = \"myję arielem ponieważ moja rodzina uwielbia zapach ariel wynik prania przekonuje mnie i jest również bardziej zrównoważony jako środek zaradczy dla mojej opinii niż detergent płynny lub kapsuły.\"\n",
    "zdanie3 = \"Nie ma różnicy między produktem w różnych krajach.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie pierwszego zdania\n",
    "if check_dual_quality_opinion(zdanie1):\n",
    "    print(\"Zdanie 1 wskazuje na podwójną jakość produktu.\")\n",
    "else:\n",
    "    print(\"Zdanie 1 nie wskazuje na podwójną jakość produktu.\")\n",
    "\n",
    "# Sprawdzenie drugiego zdania\n",
    "if check_dual_quality_opinion(zdanie2):\n",
    "    print(\"Zdanie 2 wskazuje na podwójną jakość produktu.\")\n",
    "else:\n",
    "    print(\"Zdanie 2 nie wskazuje na podwójną jakość produktu.\")\n",
    "\n",
    "# Sprawdzenie trzeciego zdania\n",
    "if check_dual_quality_opinion(zdanie3):\n",
    "    print(\"Zdanie 3 wskazuje na podwójną jakość produktu.\")\n",
    "else:\n",
    "    print(\"Zdanie 3 nie wskazuje na podwójną jakość produktu.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
